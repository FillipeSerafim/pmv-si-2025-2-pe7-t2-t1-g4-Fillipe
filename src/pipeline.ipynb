{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e3f4119-a873-4aa2-b30c-9902cbb82a4c",
   "metadata": {},
   "source": [
    "## Estruturação de um Pipeline Modular para Avaliação de Modelos\n",
    "\n",
    "### 1. Objetivo do Pipeline Modular\n",
    "\n",
    "O objetivo principal desta refatoração é transicionar da análise exploratória e modelagem sequencial (presente no *notebook* de prototipagem) para um ***framework* de experimentação robusto e generalizável**.\n",
    "\n",
    "Este *pipeline* modular visa formalizar o pré-processamento e a avaliação de múltiplos algoritmos de aprendizado de máquina de forma estruturada, programática e metodologicamente sólida. O resultado final é uma plataforma que facilita a avaliação comparativa e imparcial do desempenho de diferentes estimadores, garantindo a reprodutibilidade dos resultados.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Motivações para a Refatoração\n",
    "\n",
    "A transição de um *script* de análise manual para um *pipeline* modularizado é motivada por diversas limitações metodológicas e operacionais da abordagem anterior:\n",
    "\n",
    "* **Mitigação de *Data Leakage* (Vazamento de Dados):** Esta é a principal motivação. No *workflow* manual, o pré-processamento (ex: `StandardScaler`) é frequentemente aplicado ao conjunto de dados *antes* da divisão de validação cruzada. Isso \"contamina\" os *folds* de treino com informações estatísticas (média, desvio padrão) do conjunto de validação. O `sklearn.Pipeline` resolve isso ao garantir que o `fit` dos transformadores ocorra *exclusivamente* dentro dos dados de treino de cada *fold* da validação cruzada (`cross_validate`), simulando corretamente o desempenho em dados nunca vistos.\n",
    "* **Modularidade e Escalabilidade:** O *framework* desacopla a lógica de pré-processamento da lógica de modelagem. O `ColumnTransformer` torna-se um artefato de engenharia de *features* reutilizável, e os modelos são definidos em um dicionário (`models_to_compare`), permitindo a adição ou remoção de algoritmos (ex: `RandomForest`, `LogisticRegression`) sem reescrever o fluxo de dados.\n",
    "* **Consistência e Comparabilidade:** Ao garantir que todos os modelos recebam *exatamente* os mesmos dados de entrada (pós-processamento) e sejam avaliados sob os mesmos *folds* de validação cruzada, o *pipeline* elimina variáveis de confusão. Isso permite uma comparação direta e justa (\"apples-to-apples\") da eficácia algorítmica intrínseca de cada modelo.\n",
    "* **Generalização de Estratégias Ordinais:** A criação de um *wrapper* customizado (`OrdinalRegressorWrapper`) formaliza a abordagem de regressão ordinal. Isso permite que *qualquer* regressor compatível com `sklearn` (ex: `XGBRegressor`, `LinearRegression`) seja avaliado nesta tarefa sem a necessidade de etapas manuais de pós-processamento (como `np.round` e `np.clip`), que são propensas a erros.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Arquitetura da Solução\n",
    "\n",
    "A arquitetura da solução é centrada na interação de dois componentes principais do `scikit-learn`: `ColumnTransformer` e `Pipeline`.\n",
    "\n",
    "1.  **Identificação de Atributos:** Primeiramente, as *features* de entrada (`X_train`) foram segregadas programaticamente em dois subconjuntos mutuamente exclusivos:\n",
    "    * `numeric_features` (ex: `sales`, `ano`, `mes`)\n",
    "    * `categorical_features` (ex: `region`, `city`, `sub-category`)\n",
    "\n",
    "2.  **Transformadores Específicos:**\n",
    "    * **Numéricos:** Para o subconjunto numérico, foi definido um `numeric_transformer`, que consiste em um `Pipeline` simples contendo o `StandardScaler`. Esta etapa normaliza os dados (média zero, variância unitária), um pré-requisito para a performance ótima de modelos lineares (como `LogisticRegression`) e outros algoritmos sensíveis à escala.\n",
    "    * **Categóricos:** Para o subconjunto categórico, foi definido um `categorical_transformer`. Este aplica o `OneHotEncoder` (OHE), que transforma variáveis nominais em uma representação binária esparsa (vetorização *one-hot*). Esta é uma etapa **crítica** que torna *features* não numéricas compatíveis com a vasta maioria dos algoritmos do `sklearn`. O parâmetro `handle_unknown='ignore'` foi usado para garantir robustez, permitindo que o modelo ignore (não gere erro) se categorias não vistas no treino aparecerem na predição.\n",
    "\n",
    "3.  **Composição (ColumnTransformer):** O `ColumnTransformer` atua como o orquestrador do pré-processamento. Ele é configurado para aplicar os transformadores `num` e `cat` aos seus respectivos subconjuntos de colunas. O parâmetro `remainder='drop'` foi utilizado para descartar explicitamente quaisquer colunas não especificadas nas listas (ex: `customer_id`), prevenindo o vazamento de dados ou erros de tipo nos estimadores.\n",
    "\n",
    "4.  **Pipeline Final e Avaliação:** O `ColumnTransformer` (nomeado `preprocessor`) é encadeado como a primeira etapa de um `sklearn.Pipeline` final. O estimador (modelo) do dicionário `models_to_compare` é inserido como a segunda etapa (`model`). A função `cross_validate` é então invocada sobre este *pipeline* completo, automatizando o processo de:\n",
    "    * Dividir os dados (CV=5).\n",
    "    * Para cada *fold*, aplicar `fit_transform` do `preprocessor` nos dados de treino.\n",
    "    * Aplicar `transform` do `preprocessor` nos dados de validação.\n",
    "    * Treinar (`fit`) o modelo nos dados de treino processados.\n",
    "    * Avaliar (`score`) o modelo nos dados de validação processados.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. A Exclusão Estratégica do CatBoost\n",
    "\n",
    "O CatBoost não foi incluído neste *pipeline* comparativo por uma **razão metodológica fundamental**: sua arquitetura de processamento de *features* é incompatível com a abordagem de pré-processamento padronizada (via `OneHotEncoder`) adotada para os demais modelos.\n",
    "\n",
    "O principal diferencial competitivo do CatBoost, e a razão de seu forte desempenho no *notebook* exploratório, é seu **manuseio nativo de variáveis categóricas**. Ele não utiliza OHE, mas sim algoritmos internos de estatística-alvo (como *Target-based Statistics* e *Ordered Boosting*), que são aplicados através do objeto `catboost.Pool` ou da detecção automática de *strings*.\n",
    "\n",
    "Incluir o CatBoost neste *pipeline* significaria alimentá-lo com dados já transformados pelo `OneHotEncoder`. Isso teria duas consequências negativas:\n",
    "\n",
    "1.  **Anularia a Vantagem Competitiva:** O modelo seria privado de seu principal mecanismo de otimização de *features*, sendo forçado a tratar as *features* categóricas da mesma forma que um `RandomForest`.\n",
    "2.  **Degradaria a Eficiência:** O modelo teria que processar um *dataset* com milhares de colunas binárias esparsas (resultado do OHE em `city` ou `state`), para o qual não é otimizado, em vez de um *dataset* enxuto com *features* categóricas brutas.\n",
    "\n",
    "Portanto, uma comparação justa exigiria um *pipeline* de avaliação separado para o CatBoost, onde as *features* numéricas são escaladas, mas as categóricas são passadas como *strings* brutas (`remainder='passthrough'`), permitindo que o algoritmo aplique sua lógica interna. A comparação, neste caso, não seria apenas entre algoritmos, mas entre *estratégias de processamento* distintas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c6de003-523e-495d-9408-5e26eb1f4e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, mean_absolute_error\n",
    "\n",
    "# Para a Abordagem B (Regressão Ordinal)\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa74999-e95d-4ffa-a98b-a7d8c938ba0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train e y_train criados com sucesso.\n",
      "Shape do X_train: (6542, 15)\n"
     ]
    }
   ],
   "source": [
    "# --- Carregamento e Limpeza (Etapas Faltantes) ---\n",
    "data_path = Path('data/train.csv')\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "# 1. PADRONIZAÇÃO DE COLUNAS (O passo que causou o erro)\n",
    "df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "\n",
    "# 2. LIMPEZA (Agora 'postal_code' existe)\n",
    "df['postal_code'] = df['postal_code'].fillna(5401)\n",
    "# (Assumindo 'dayfirst=True' do notebook original)\n",
    "df['order_date'] = pd.to_datetime(df['order_date'], dayfirst=True) \n",
    "\n",
    "# 3. CRIAÇÃO DA VARIÁVEL ALVO ('demand')\n",
    "product_demand = df.groupby('product_id')['sales'].sum().reset_index()\n",
    "\n",
    "# (Etapa de qcut faltando no seu código, mas presente no original)\n",
    "labels = ['very low', 'low', 'neutral', 'high', 'very high']\n",
    "product_demand['demand'] = pd.qcut(product_demand['sales'], q=5, labels=labels)\n",
    "\n",
    "df = pd.merge(\n",
    "    left=df,\n",
    "    right=product_demand[['product_id', 'demand']],\n",
    "    on='product_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 4. CRIAÇÃO DO TARGET NUMÉRICO ('demand_ord')\n",
    "ordinal_mapping = {\n",
    "    'very low': 0,\n",
    "    'low': 1,\n",
    "    'neutral': 2,\n",
    "    'high': 3,\n",
    "    'very high': 4\n",
    "}\n",
    "# Criamos no 'df' todo antes de fatiar\n",
    "df['demand_ord'] = df['demand'].map(ordinal_mapping)\n",
    "# (Tratamento de nulos caso o qcut ou merge falhem - o original não tinha, mas é boa prática)\n",
    "df = df.dropna(subset=['demand_ord']) # Garante que o alvo não seja nulo\n",
    "df['demand_ord'] = df['demand_ord'].astype('int8')\n",
    "\n",
    "\n",
    "# 5. FEATURE ENGINEERING (Para 'ano', 'mes', 'dia_semana', etc.)\n",
    "df['ano'] = df['order_date'].dt.year\n",
    "df['mes'] = df['order_date'].dt.month\n",
    "df['dia_semana'] = df['order_date'].dt.day_name(locale='pt_BR')\n",
    "df['day_of_week'] = df['order_date'].dt.day_name() # Versão em inglês\n",
    "\n",
    "# --- Divisão e Definição de X/y ---\n",
    "\n",
    "df_treino = df[(df['order_date'] >= '2015-01-01') & (df['order_date'] <= '2017-12-31')].copy()\n",
    "\n",
    "# 6. DEFINIÇÃO DE COLS_TO_DROP (Faltando no seu script)\n",
    "# (Lista do notebook original, garantindo que 'product_id' saia)\n",
    "cols_to_drop = [\n",
    "    'demand', 'demand_ord', 'row_id', 'order_id', 'customer_name',\n",
    "    'product_name', 'order_date', 'ship_date', 'product_id'\n",
    "]\n",
    "\n",
    "# 5. Definir seus dados de treino (Agora deve funcionar)\n",
    "X_train = df_treino.drop(columns=cols_to_drop, errors='ignore')\n",
    "y_train = df_treino['demand_ord']\n",
    "\n",
    "print(\"X_train e y_train criados com sucesso.\")\n",
    "print(f\"Shape do X_train: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4c238d9-b6e6-4774-8386-3b2051919f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definir os grupos de colunas\n",
    "numeric_features = ['sales', 'postal_code', 'ano', 'mes'] # Adicione outras se houver\n",
    "categorical_features = ['ship_mode', 'segment', 'city', 'state', \n",
    "                        'region', 'category', 'sub-category', \n",
    "                        'dia_semana', 'day_of_week']\n",
    "\n",
    "# 2. Criar o transformador numérico\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# 3. Criar o transformador categórico\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "# 4. Unir tudo com o ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# 5. Definir seus dados de treino\n",
    "# (Usando o df_treino antes de qualquer processamento manual)\n",
    "X_train = df_treino.drop(columns=cols_to_drop, errors='ignore')\n",
    "y_train = df_treino['demand_ord']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee9e8863-7466-49d7-b9f9-02744a572750",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinalRegressorWrapper(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"\n",
    "    Wrapper que transforma um regressor em um classificador ordinal.\n",
    "    Ele treina o regressor no target numérico (0-4) e, na predição,\n",
    "    arredonda e limita (clip) o resultado para a classe inteira mais próxima.\n",
    "    \"\"\"\n",
    "    def __init__(self, regressor, min_val=0, max_val=4):\n",
    "        self.regressor = regressor\n",
    "        self.min_val = min_val\n",
    "        self.max_val = max_val\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # O 'regressor' (ex: XGBRegressor) é 'fitado' normalmente\n",
    "        self.regressor.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # 1. Prever o valor float\n",
    "        preds_float = self.regressor.predict(X)\n",
    "        \n",
    "        # 2. Arredondar para o inteiro mais próximo\n",
    "        preds_rounded = np.round(preds_float)\n",
    "        \n",
    "        # 3. Limitar (clip) ao intervalo de classes [0, 4]\n",
    "        preds_clipped = np.clip(preds_rounded, self.min_val, self.max_val)\n",
    "        \n",
    "        return preds_clipped.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db18158c-b5e3-4bb8-8590-98710f57090d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "# Dicionário de modelos para testar\n",
    "models_to_compare = {\n",
    "    'LogisticRegression_Multi': LogisticRegression(solver='liblinear', multi_class='ovr', random_state=42),\n",
    "    'RandomForest_Multi': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'LGBM_Multi': lgb.LGBMClassifier(objective='multiclass', num_class=5, random_state=42),\n",
    "    'XGBoost_Reg': OrdinalRegressorWrapper(\n",
    "        regressor=xgb.XGBRegressor(objective='reg:squarederror', \n",
    "                                   random_state=42, \n",
    "                                   n_estimators=100),\n",
    "        min_val=0,\n",
    "        max_val=4\n",
    "    )\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a7626d2-3cfb-4437-a56e-54a1878c77b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando avaliação de múltiplos modelos...\n",
      "--- Avaliando: LogisticRegression_Multi ---\n",
      "--- Avaliando: RandomForest_Multi ---\n",
      "--- Avaliando: LGBM_Multi ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jusbrasil/dg_dev/kfcaio-pmv-si-2025-2-pe7-t2-t1-g4/src/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/jusbrasil/dg_dev/kfcaio-pmv-si-2025-2-pe7-t2-t1-g4/src/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/jusbrasil/dg_dev/kfcaio-pmv-si-2025-2-pe7-t2-t1-g4/src/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/jusbrasil/dg_dev/kfcaio-pmv-si-2025-2-pe7-t2-t1-g4/src/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/jusbrasil/dg_dev/kfcaio-pmv-si-2025-2-pe7-t2-t1-g4/src/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Avaliando: XGBoost_Reg ---\n",
      "... Avaliação concluída.\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000190 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 5234, number of used features: 122\n",
      "[LightGBM] [Info] Start training from score -1.940195\n",
      "[LightGBM] [Info] Start training from score -1.573596\n",
      "[LightGBM] [Info] Start training from score -1.619809\n",
      "[LightGBM] [Info] Start training from score -1.578215\n",
      "[LightGBM] [Info] Start training from score -1.407535\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000896 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5234, number of used features: 127\n",
      "[LightGBM] [Info] Start training from score -1.940195\n",
      "[LightGBM] [Info] Start training from score -1.573596\n",
      "[LightGBM] [Info] Start training from score -1.619809\n",
      "[LightGBM] [Info] Start training from score -1.578215\n",
      "[LightGBM] [Info] Start training from score -1.407535\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000155 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 5233, number of used features: 130\n",
      "[LightGBM] [Info] Start training from score -1.940004\n",
      "[LightGBM] [Info] Start training from score -1.574327\n",
      "[LightGBM] [Info] Start training from score -1.619618\n",
      "[LightGBM] [Info] Start training from score -1.578024\n",
      "[LightGBM] [Info] Start training from score -1.407344\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.004842 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 770\n",
      "[LightGBM] [Info] Number of data points in the train set: 5234, number of used features: 129\n",
      "[LightGBM] [Info] Start training from score -1.940195\n",
      "[LightGBM] [Info] Start training from score -1.573596\n",
      "[LightGBM] [Info] Start training from score -1.619809\n",
      "[LightGBM] [Info] Start training from score -1.578215\n",
      "[LightGBM] [Info] Start training from score -1.407535\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001074 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 773\n",
      "[LightGBM] [Info] Number of data points in the train set: 5233, number of used features: 130\n",
      "[LightGBM] [Info] Start training from score -1.940004\n",
      "[LightGBM] [Info] Start training from score -1.574327\n",
      "[LightGBM] [Info] Start training from score -1.619618\n",
      "[LightGBM] [Info] Start training from score -1.578024\n",
      "[LightGBM] [Info] Start training from score -1.407344\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000538 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 770\n",
      "[LightGBM] [Info] Number of data points in the train set: 5234, number of used features: 129\n",
      "[LightGBM] [Info] Start training from score -1.940195\n",
      "[LightGBM] [Info] Start training from score -1.573596\n",
      "[LightGBM] [Info] Start training from score -1.619809\n",
      "[LightGBM] [Info] Start training from score -1.578215\n",
      "[LightGBM] [Info] Start training from score -1.407535\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001087 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5233, number of used features: 126\n",
      "[LightGBM] [Info] Start training from score -1.940004\n",
      "[LightGBM] [Info] Start training from score -1.573405\n",
      "[LightGBM] [Info] Start training from score -1.619618\n",
      "[LightGBM] [Info] Start training from score -1.578024\n",
      "[LightGBM] [Info] Start training from score -1.408125\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000874 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5234, number of used features: 127\n",
      "[LightGBM] [Info] Start training from score -1.940195\n",
      "[LightGBM] [Info] Start training from score -1.573596\n",
      "[LightGBM] [Info] Start training from score -1.619809\n",
      "[LightGBM] [Info] Start training from score -1.578215\n",
      "[LightGBM] [Info] Start training from score -1.407535\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000092 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 766\n",
      "[LightGBM] [Info] Number of data points in the train set: 5233, number of used features: 126\n",
      "[LightGBM] [Info] Start training from score -1.940004\n",
      "[LightGBM] [Info] Start training from score -1.573405\n",
      "[LightGBM] [Info] Start training from score -1.619618\n",
      "[LightGBM] [Info] Start training from score -1.578024\n",
      "[LightGBM] [Info] Start training from score -1.408125\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 757\n",
      "[LightGBM] [Info] Number of data points in the train set: 5234, number of used features: 122\n",
      "[LightGBM] [Info] Start training from score -1.940195\n",
      "[LightGBM] [Info] Start training from score -1.573596\n",
      "[LightGBM] [Info] Start training from score -1.619809\n",
      "[LightGBM] [Info] Start training from score -1.578215\n",
      "[LightGBM] [Info] Start training from score -1.407535\n"
     ]
    }
   ],
   "source": [
    "# Usamos 'neg_mean_absolute_error' pois o sklearn maximiza scores (erro negativo)\n",
    "scoring_metrics = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'mae': 'neg_mean_absolute_error'\n",
    "}\n",
    "\n",
    "# Lista para armazenar os resultados\n",
    "cv_results = []\n",
    "\n",
    "# Iterar sobre cada modelo no dicionário\n",
    "print(\"Iniciando avaliação de múltiplos modelos...\")\n",
    "for model_name, model in models_to_compare.items():\n",
    "    \n",
    "    print(f\"--- Avaliando: {model_name} ---\")\n",
    "    \n",
    "    # 1. Criar o Pipeline completo: Preprocessor -> Model\n",
    "    full_pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "    \n",
    "    # 2. Executar a Validação Cruzada (ex: 5 folds)\n",
    "    # X_train e y_train são os dados BRUTOS (antes do pré-processamento)\n",
    "    scores = cross_validate(\n",
    "        full_pipeline, \n",
    "        X_train, \n",
    "        y_train, \n",
    "        cv=5, \n",
    "        scoring=scoring_metrics,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # 3. Armazenar os resultados médios\n",
    "    cv_results.append({\n",
    "        'Modelo': model_name,\n",
    "        'Accuracy_Média': scores['test_accuracy'].mean(),\n",
    "        'MAE_Média': -1 * scores['test_mae'].mean() # Corrigindo o sinal do MAE\n",
    "    })\n",
    "\n",
    "print(\"... Avaliação concluída.\")\n",
    "\n",
    "# 6. Consolidar e Apresentar Resultados\n",
    "df_comparacao_cv = pd.DataFrame(cv_results).set_index('Modelo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb4b50a2-f331-41e4-b6bb-43b9d1f94e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela Comparativa de Métricas (Validação Cruzada, 5-Folds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_611b3_row3_col0, #T_611b3_row3_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_611b3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_611b3_level0_col0\" class=\"col_heading level0 col0\" >Accuracy_Média</th>\n",
       "      <th id=\"T_611b3_level0_col1\" class=\"col_heading level0 col1\" >MAE_Média</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Modelo</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_611b3_level0_row0\" class=\"row_heading level0 row0\" >LogisticRegression_Multi</th>\n",
       "      <td id=\"T_611b3_row0_col0\" class=\"data row0 col0\" >0.5136</td>\n",
       "      <td id=\"T_611b3_row0_col1\" class=\"data row0 col1\" >0.6033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_611b3_level0_row1\" class=\"row_heading level0 row1\" >RandomForest_Multi</th>\n",
       "      <td id=\"T_611b3_row1_col0\" class=\"data row1 col0\" >0.5402</td>\n",
       "      <td id=\"T_611b3_row1_col1\" class=\"data row1 col1\" >0.5459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_611b3_level0_row2\" class=\"row_heading level0 row2\" >LGBM_Multi</th>\n",
       "      <td id=\"T_611b3_row2_col0\" class=\"data row2 col0\" >0.5717</td>\n",
       "      <td id=\"T_611b3_row2_col1\" class=\"data row2 col1\" >0.4859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_611b3_level0_row3\" class=\"row_heading level0 row3\" >XGBoost_Reg</th>\n",
       "      <td id=\"T_611b3_row3_col0\" class=\"data row3 col0\" >0.5876</td>\n",
       "      <td id=\"T_611b3_row3_col1\" class=\"data row3 col1\" >0.4482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1162e69d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exibir a tabela comparativa final\n",
    "print(\"Tabela Comparativa de Métricas (Validação Cruzada, 5-Folds)\")\n",
    "display(df_comparacao_cv.style.format({\n",
    "    'Accuracy_Média': '{:.4f}',\n",
    "    'MAE_Média': '{:.4f}'\n",
    "}).highlight_max(subset=['Accuracy_Média'], color='lightgreen')\n",
    "  .highlight_min(subset=['MAE_Média'], color='lightgreen')\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
